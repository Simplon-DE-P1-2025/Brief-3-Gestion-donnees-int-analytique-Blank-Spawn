# Brief-3-Gestion-donnees-int-analytique-Blank-Spawn
- Gestion de donn√©es et interface analytique

## Contexte
Projet de centralisation et visualisation des donn√©es pour le d√©partement de surveillance et sauvetage.

## üéØ Objectifs
- R√©cup√©rer et nettoyer les donn√©es
- Centraliser dans une base (SQLite/Postgres)
- Cr√©er une interface CRUD et un dashboard analytique (Streamlit/Power BI)
- Documenter et tester (Pytest, Pandera)

## üõ†Ô∏è Stack technique
Python, Pandera, Streamlit, Pytest, SQLite/Postgres, Docker

## üìÅ Explication de la structure du projet

Le point d'entr√©e du pipeline: `pipeline/main.py`

Dossiers:
- pipeline - contient tous les fichiers en lien direct avec l'√©xecution du flux ETL.
- streamlit_app - code streamlit pour les end users
- support_tools - r√©pertorie les scripts utilis√©s tout au long du d√©veloppement du projet
- tests - r√©pertorie les fonctions de test, √† utiliser avec pytest

## üöÄ Lancement du projet en local

### Installation des d√©pendances
Avant de lancer les tests, assurez-vous d'installer les d√©pendances :
```bash
pip install -r requirements.txt
```

### Activation de l'environnement virtuel
Activez l'environnement virtuel Python :
```bash
source .venv/bin/activate
```

### Fichiers d'environnement
Le projet utilisant une base de donn√©es h√©berg√©e en ligne, nous utilisons des fichiers d'environnement pour stocker des variables n√©cessaires √† la connexion en BDD.
Un premier fichier `.env` √† placer √† la racine du projet:

Les donn√©es n√©cessaires dans ces fichiers
- SUPABASE_URL= `URL de connexion √† Supabase`
- SUPABASE_KEY= `cl√© Supabase`
- user= `utilisateur de base de donn√©es`
- password= `mot de passe utilisateur`
- host= `IP/Nom d'h√¥te pour la connexion √† la base`
- port= `port de connexion`
- dbname= `nom de la base`

### Lancement
```bash
python3 pipeline/main.py
```

## üê≥ Lancement du projet avec Docker Compose

Pour utiliser Docker Compose afin de lancer la base de donn√©es PostgreSQL localement :

### Pr√©requis
- Docker et Docker Compose install√©s sur votre machine.
- Fichier `.env` configur√© avec les variables d'environnement n√©cessaires (voir section "Fichiers d'environnement").

### D√©marrage de la base de donn√©es
```bash
docker-compose up -d
```
Cette commande lance le conteneur PostgreSQL en arri√®re-plan. Le service sera accessible sur le port d√©fini dans la variable `POSTGRES_PORT` du fichier `.env`.

### Arr√™t de la base de donn√©es
```bash
docker-compose down
```
Cela arr√™te et supprime les conteneurs lanc√©s par Docker Compose.

Apr√®s avoir d√©marr√© la base de donn√©es avec Docker Compose, vous pouvez lancer le pipeline comme indiqu√© dans la section "Lancement du projet en local".

## Structure de la base
<div align="center">
  <img src="assets/schema.png" alt="schema BDD">
</div>

## ‚úÖ Tests unitaires et Couverture

### Ex√©cution des tests
Pour ex√©cuter tous les tests du projet :
```bash
pytest -v
```

### V√©rification de la couverture du code
Pour g√©n√©rer un rapport de couverture du code :
```bash
pytest --cov=src --cov-report=term-missing
```
Le rapport sera g√©n√©r√© directement dans le terminal.