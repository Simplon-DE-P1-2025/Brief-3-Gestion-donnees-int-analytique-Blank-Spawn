{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "454e9bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3694b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26744/303084641.py:2: DtypeWarning: Columns (1,2,11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  operations = pd.read_csv(\"../data/operations.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== OPERATIONS ===\n",
      "   operation_id type_operation pourquoi_alerte              moyen_alerte  \\\n",
      "0       -135614            MAS             NaN                VHF phonie   \n",
      "1       -135613            SAR             NaN  T√©l√©phone mobile √† terre   \n",
      "2       -135598            MAS             NaN            T√©l√©phone fixe   \n",
      "3       -135597            MAS             NaN                VHF phonie   \n",
      "4       -135596            SAR             NaN        Balise de d√©tresse   \n",
      "\n",
      "                           qui_alerte                  categorie_qui_alerte  \\\n",
      "0                     Navire impliqu√©                       Navire √† la mer   \n",
      "1        CORG / Gendarmerie nationale  Autorit√© militaire fran√ßaise √† terre   \n",
      "2  Autre organisme ou personne priv√©e          Organisme ou personne priv√©e   \n",
      "3                     Navire impliqu√©                       Navire √† la mer   \n",
      "4                        CROSS / MRCC     Autorit√© civile fran√ßaise √† terre   \n",
      "\n",
      "                cross         departement  est_metropolitain  \\\n",
      "0  Nouvelle-Cal√©donie  Nouvelle-Cal√©donie              False   \n",
      "1  Nouvelle-Cal√©donie                 NaN              False   \n",
      "2  Nouvelle-Cal√©donie  Nouvelle-Cal√©donie              False   \n",
      "3  Nouvelle-Cal√©donie  Nouvelle-Cal√©donie              False   \n",
      "4  Nouvelle-Cal√©donie  Nouvelle-Cal√©donie              False   \n",
      "\n",
      "                         evenement  ... vent_direction  \\\n",
      "0  Avarie du syst√®me de propulsion  ...            NaN   \n",
      "1                         Baignade  ...          100.0   \n",
      "2  Avarie du syst√®me de propulsion  ...          270.0   \n",
      "3  Avarie du syst√®me de propulsion  ...           90.0   \n",
      "4           Toutes fausses alertes  ...           80.0   \n",
      "\n",
      "  vent_direction_categorie vent_force mer_force  date_heure_reception_alerte  \\\n",
      "0                      NaN        NaN       NaN    2025-06-11 22:50:00+00:00   \n",
      "1                      est        4.0       3.0    2025-06-30 01:10:00+00:00   \n",
      "2                    ouest        4.0       2.0    2025-06-13 19:30:00+00:00   \n",
      "3                      est        4.0       3.0    2025-06-13 09:15:00+00:00   \n",
      "4                      est        2.0       1.0    2025-06-12 21:38:00+00:00   \n",
      "\n",
      "    date_heure_fin_operation  numero_sitrep                     cross_sitrep  \\\n",
      "0  2025-06-12 00:55:00+00:00            166  Nouvelle-Cal√©donie MAS 2025/166   \n",
      "1  2025-06-30 02:05:00+00:00            184  Nouvelle-Cal√©donie SAR 2025/184   \n",
      "2  2025-06-13 23:08:00+00:00            169  Nouvelle-Cal√©donie MAS 2025/169   \n",
      "3  2025-06-13 15:00:00+00:00            168  Nouvelle-Cal√©donie MAS 2025/168   \n",
      "4  2025-06-13 21:48:00+00:00            167  Nouvelle-Cal√©donie SAR 2025/167   \n",
      "\n",
      "   fuseau_horaire  systeme_source  \n",
      "0  Pacific/Noumea       secmarweb  \n",
      "1  Pacific/Noumea       secmarweb  \n",
      "2  Pacific/Noumea       secmarweb  \n",
      "3  Pacific/Noumea       secmarweb  \n",
      "4  Pacific/Noumea       secmarweb  \n",
      "\n",
      "[5 rows x 26 columns] \n",
      "\n",
      "=== RESULTATS HUMAIN ===\n",
      "   operation_id    categorie_personne                        resultat_humain  \\\n",
      "0       -135614      P√™cheur fran√ßais         Personne tir√©e d'affaire seule   \n",
      "1       -135613  Plaisancier fran√ßais  Personne impliqu√©e dans fausse alerte   \n",
      "2       -135598      P√™cheur fran√ßais                      Personne assist√©e   \n",
      "3       -135597        Marin √©tranger                      Personne assist√©e   \n",
      "4       -135596  Plaisancier fran√ßais  Personne impliqu√©e dans fausse alerte   \n",
      "\n",
      "   nombre  dont_nombre_blesse  \n",
      "0       6                   0  \n",
      "1       1                   0  \n",
      "2       2                   0  \n",
      "3      19                   0  \n",
      "4       1                   0   \n",
      "\n",
      "=== FLOTTEURS ===\n",
      "   operation_id  numero_ordre  pavillon  \\\n",
      "0       -135614           1.0  Fran√ßais   \n",
      "1       -135598           1.0  Fran√ßais   \n",
      "2       -135597           1.0  √âtranger   \n",
      "3       -135596           1.0  √âtranger   \n",
      "4       -135595           1.0  √âtranger   \n",
      "\n",
      "                        resultat_flotteur                     type_flotteur  \\\n",
      "0  Difficult√© surmont√©e, reprise de route                             P√™che   \n",
      "1                                Remorqu√©           Plaisance √† moteur < 8m   \n",
      "2                                 Assist√©  Navire de charge ou de servitude   \n",
      "3       Non assist√©, cas de fausse alerte                 Plaisance √† voile   \n",
      "4       Non assist√©, cas de fausse alerte  Navire de charge ou de servitude   \n",
      "\n",
      "  categorie_flotteur numero_immatriculation  \n",
      "0              P√™che                    NaN  \n",
      "1          Plaisance                    NaN  \n",
      "2           Commerce                    NaN  \n",
      "3          Plaisance                    NaN  \n",
      "4           Commerce                    NaN   \n",
      "\n",
      "=== INFO OPERATIONS ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 385782 entries, 0 to 385781\n",
      "Data columns (total 26 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   operation_id                 385782 non-null  int64  \n",
      " 1   type_operation               209341 non-null  object \n",
      " 2   pourquoi_alerte              176441 non-null  object \n",
      " 3   moyen_alerte                 383890 non-null  object \n",
      " 4   qui_alerte                   384054 non-null  object \n",
      " 5   categorie_qui_alerte         384054 non-null  object \n",
      " 6   cross                        385782 non-null  object \n",
      " 7   departement                  309298 non-null  object \n",
      " 8   est_metropolitain            385782 non-null  bool   \n",
      " 9   evenement                    381859 non-null  object \n",
      " 10  categorie_evenement          381859 non-null  object \n",
      " 11  autorite                     305679 non-null  object \n",
      " 12  seconde_autorite             15036 non-null   object \n",
      " 13  zone_responsabilite          385067 non-null  object \n",
      " 14  latitude                     331320 non-null  float64\n",
      " 15  longitude                    331320 non-null  float64\n",
      " 16  vent_direction               281797 non-null  float64\n",
      " 17  vent_direction_categorie     270754 non-null  object \n",
      " 18  vent_force                   281854 non-null  float64\n",
      " 19  mer_force                    274569 non-null  float64\n",
      " 20  date_heure_reception_alerte  385782 non-null  object \n",
      " 21  date_heure_fin_operation     385782 non-null  object \n",
      " 22  numero_sitrep                385782 non-null  int64  \n",
      " 23  cross_sitrep                 385782 non-null  object \n",
      " 24  fuseau_horaire               385782 non-null  object \n",
      " 25  systeme_source               385782 non-null  object \n",
      "dtypes: bool(1), float64(5), int64(2), object(18)\n",
      "memory usage: 74.0+ MB\n",
      "None \n",
      "\n",
      "=== INFO RESULTATS HUMAIN ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 290544 entries, 0 to 290543\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   operation_id        290544 non-null  int64 \n",
      " 1   categorie_personne  290544 non-null  object\n",
      " 2   resultat_humain     290544 non-null  object\n",
      " 3   nombre              290544 non-null  int64 \n",
      " 4   dont_nombre_blesse  290544 non-null  int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 11.1+ MB\n",
      "None \n",
      "\n",
      "=== INFO FLOTTEURS ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 315191 entries, 0 to 315190\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   operation_id            315191 non-null  int64  \n",
      " 1   numero_ordre            244793 non-null  float64\n",
      " 2   pavillon                293395 non-null  object \n",
      " 3   resultat_flotteur       311152 non-null  object \n",
      " 4   type_flotteur           312585 non-null  object \n",
      " 5   categorie_flotteur      312585 non-null  object \n",
      " 6   numero_immatriculation  136584 non-null  object \n",
      "dtypes: float64(1), int64(1), object(5)\n",
      "memory usage: 16.8+ MB\n",
      "None \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Charger les fichiers CSV\n",
    "operations = pd.read_csv(\"../data/operations.csv\")\n",
    "resultats_humain = pd.read_csv(\"../data/resultats_humain.csv\")\n",
    "flotteurs = pd.read_csv(\"../data/flotteurs.csv\")\n",
    "\n",
    "# Afficher les premi√®res lignes\n",
    "print(\"=== OPERATIONS ===\")\n",
    "print(operations.head(), \"\\n\")\n",
    "\n",
    "print(\"=== RESULTATS HUMAIN ===\")\n",
    "print(resultats_humain.head(), \"\\n\")\n",
    "\n",
    "print(\"=== FLOTTEURS ===\")\n",
    "print(flotteurs.head(), \"\\n\")\n",
    "\n",
    "# V√©rifier les infos sur les colonnes et types\n",
    "print(\"=== INFO OPERATIONS ===\")\n",
    "print(operations.info(), \"\\n\")\n",
    "\n",
    "print(\"=== INFO RESULTATS HUMAIN ===\")\n",
    "print(resultats_humain.info(), \"\\n\")\n",
    "\n",
    "print(\"=== INFO FLOTTEURS ===\")\n",
    "print(flotteurs.info(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8aec80",
   "metadata": {},
   "source": [
    "Pour chaque table, nous avons analys√© :\n",
    "\n",
    "    le nombre de lignes et colonnes,\n",
    "\n",
    "    les types de donn√©es,\n",
    "\n",
    "    les valeurs manquantes,\n",
    "\n",
    "    les doublons,\n",
    "\n",
    "    les valeurs aberrantes,\n",
    "\n",
    "    la coh√©rence des dates,\n",
    "\n",
    "    la coh√©rence de la cl√© operation_id.\n",
    "\n",
    "Les r√©sultats de cet audit ont permis de d√©finir les r√®gles de nettoyage (voir section suivante)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f59bc408",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def audit_table(df, table_name):\n",
    "    print(f\"\\n================ AUDIT : {table_name} ================\")\n",
    "\n",
    "    # Dimensions\n",
    "    print(f\"Nombre de lignes : {df.shape[0]}\")\n",
    "    print(f\"Nombre de colonnes : {df.shape[1]}\")\n",
    "\n",
    "    # Colonnes\n",
    "    print(\"\\nColonnes :\")\n",
    "    print(df.columns.tolist())\n",
    "\n",
    "    # Types\n",
    "    print(\"\\nTypes des colonnes :\")\n",
    "    print(df.dtypes)\n",
    "\n",
    "    # Valeurs manquantes\n",
    "    print(\"\\nValeurs manquantes :\")\n",
    "    print(df.isna().sum())\n",
    "\n",
    "    # Doublons\n",
    "    print(\"\\nNombre de doublons :\")\n",
    "    print(df.duplicated().sum())\n",
    "\n",
    "    # Statistiques descriptives\n",
    "    print(\"\\nStatistiques descriptives :\")\n",
    "    print(df.describe(include='all'))\n",
    "\n",
    "    # V√©rification des colonnes date/heure\n",
    "    print(\"\\nV√©rification des colonnes date/heure :\")\n",
    "    for col in df.columns:\n",
    "        if \"date\" in col.lower() or \"time\" in col.lower():\n",
    "            try:\n",
    "                pd.to_datetime(df[col])\n",
    "                print(f\"{col} : format date valide\")\n",
    "            except:\n",
    "                print(f\" {col} : format date NON valide\")\n",
    "\n",
    "    print(\"=====================================================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35c1b757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ AUDIT : operations ================\n",
      "Nombre de lignes : 385782\n",
      "Nombre de colonnes : 26\n",
      "\n",
      "Colonnes :\n",
      "['operation_id', 'type_operation', 'pourquoi_alerte', 'moyen_alerte', 'qui_alerte', 'categorie_qui_alerte', 'cross', 'departement', 'est_metropolitain', 'evenement', 'categorie_evenement', 'autorite', 'seconde_autorite', 'zone_responsabilite', 'latitude', 'longitude', 'vent_direction', 'vent_direction_categorie', 'vent_force', 'mer_force', 'date_heure_reception_alerte', 'date_heure_fin_operation', 'numero_sitrep', 'cross_sitrep', 'fuseau_horaire', 'systeme_source']\n",
      "\n",
      "Types des colonnes :\n",
      "operation_id                     int64\n",
      "type_operation                  object\n",
      "pourquoi_alerte                 object\n",
      "moyen_alerte                    object\n",
      "qui_alerte                      object\n",
      "categorie_qui_alerte            object\n",
      "cross                           object\n",
      "departement                     object\n",
      "est_metropolitain                 bool\n",
      "evenement                       object\n",
      "categorie_evenement             object\n",
      "autorite                        object\n",
      "seconde_autorite                object\n",
      "zone_responsabilite             object\n",
      "latitude                       float64\n",
      "longitude                      float64\n",
      "vent_direction                 float64\n",
      "vent_direction_categorie        object\n",
      "vent_force                     float64\n",
      "mer_force                      float64\n",
      "date_heure_reception_alerte     object\n",
      "date_heure_fin_operation        object\n",
      "numero_sitrep                    int64\n",
      "cross_sitrep                    object\n",
      "fuseau_horaire                  object\n",
      "systeme_source                  object\n",
      "dtype: object\n",
      "\n",
      "Valeurs manquantes :\n",
      "operation_id                        0\n",
      "type_operation                 176441\n",
      "pourquoi_alerte                209341\n",
      "moyen_alerte                     1892\n",
      "qui_alerte                       1728\n",
      "categorie_qui_alerte             1728\n",
      "cross                               0\n",
      "departement                     76484\n",
      "est_metropolitain                   0\n",
      "evenement                        3923\n",
      "categorie_evenement              3923\n",
      "autorite                        80103\n",
      "seconde_autorite               370746\n",
      "zone_responsabilite               715\n",
      "latitude                        54462\n",
      "longitude                       54462\n",
      "vent_direction                 103985\n",
      "vent_direction_categorie       115028\n",
      "vent_force                     103928\n",
      "mer_force                      111213\n",
      "date_heure_reception_alerte         0\n",
      "date_heure_fin_operation            0\n",
      "numero_sitrep                       0\n",
      "cross_sitrep                        0\n",
      "fuseau_horaire                      0\n",
      "systeme_source                      0\n",
      "dtype: int64\n",
      "\n",
      "Nombre de doublons :\n",
      "0\n",
      "\n",
      "Statistiques descriptives :\n",
      "        operation_id type_operation    pourquoi_alerte       moyen_alerte  \\\n",
      "count   3.857820e+05         209341             176441             383890   \n",
      "unique           NaN              4                 11                 33   \n",
      "top              NaN            SAR  √âv√©nement reconnu  T√©l√©phone √† terre   \n",
      "freq             NaN         102069             114817             105613   \n",
      "mean    3.534151e+09            NaN                NaN                NaN   \n",
      "std     6.828414e+09            NaN                NaN                NaN   \n",
      "min    -1.356140e+05            NaN                NaN                NaN   \n",
      "25%    -3.403475e+04            NaN                NaN                NaN   \n",
      "50%     2.119951e+09            NaN                NaN                NaN   \n",
      "75%     3.120021e+09            NaN                NaN                NaN   \n",
      "max     1.104202e+11            NaN                NaN                NaN   \n",
      "\n",
      "             qui_alerte categorie_qui_alerte   cross departement  \\\n",
      "count            384054               384054  385782      309298   \n",
      "unique               82                    7      17          38   \n",
      "top     Navire impliqu√©      Navire √† la mer    √âtel         Var   \n",
      "freq              97827               135803   94798       29571   \n",
      "mean                NaN                  NaN     NaN         NaN   \n",
      "std                 NaN                  NaN     NaN         NaN   \n",
      "min                 NaN                  NaN     NaN         NaN   \n",
      "25%                 NaN                  NaN     NaN         NaN   \n",
      "50%                 NaN                  NaN     NaN         NaN   \n",
      "75%                 NaN                  NaN     NaN         NaN   \n",
      "max                 NaN                  NaN     NaN         NaN   \n",
      "\n",
      "       est_metropolitain               evenement  ... vent_direction  \\\n",
      "count             385782                  381859  ...  281797.000000   \n",
      "unique                 2                      68  ...            NaN   \n",
      "top                 True  Toutes fausses alertes  ...            NaN   \n",
      "freq              334464                   61216  ...            NaN   \n",
      "mean                 NaN                     NaN  ...     187.660529   \n",
      "std                  NaN                     NaN  ...     104.381924   \n",
      "min                  NaN                     NaN  ...       0.000000   \n",
      "25%                  NaN                     NaN  ...      90.000000   \n",
      "50%                  NaN                     NaN  ...     208.000000   \n",
      "75%                  NaN                     NaN  ...     272.000000   \n",
      "max                  NaN                     NaN  ...     360.000000   \n",
      "\n",
      "       vent_direction_categorie     vent_force      mer_force  \\\n",
      "count                    270754  281854.000000  274569.000000   \n",
      "unique                        8            NaN            NaN   \n",
      "top                       ouest            NaN            NaN   \n",
      "freq                      53417            NaN            NaN   \n",
      "mean                        NaN       3.548195       2.663564   \n",
      "std                         NaN       1.675643       1.079026   \n",
      "min                         NaN       0.000000       0.000000   \n",
      "25%                         NaN       2.000000       2.000000   \n",
      "50%                         NaN       3.000000       3.000000   \n",
      "75%                         NaN       4.000000       3.000000   \n",
      "max                         NaN      12.000000       9.000000   \n",
      "\n",
      "        date_heure_reception_alerte   date_heure_fin_operation  numero_sitrep  \\\n",
      "count                        385782                     385782  385782.000000   \n",
      "unique                       378582                     375972            NaN   \n",
      "top       1995-08-17 04:55:00+00:00  2022-08-04 14:00:00+00:00            NaN   \n",
      "freq                              7                          7            NaN   \n",
      "mean                            NaN                        NaN    1053.862630   \n",
      "std                             NaN                        NaN    1033.913984   \n",
      "min                             NaN                        NaN       0.000000   \n",
      "25%                             NaN                        NaN     291.000000   \n",
      "50%                             NaN                        NaN     701.000000   \n",
      "75%                             NaN                        NaN    1499.000000   \n",
      "max                             NaN                        NaN   22622.000000   \n",
      "\n",
      "       cross_sitrep  fuseau_horaire  systeme_source  \n",
      "count        385782          385782          385782  \n",
      "unique       385694               9               2  \n",
      "top     √âtel 2003/3    Europe/Paris       secmarweb  \n",
      "freq              2          334469          305679  \n",
      "mean            NaN             NaN             NaN  \n",
      "std             NaN             NaN             NaN  \n",
      "min             NaN             NaN             NaN  \n",
      "25%             NaN             NaN             NaN  \n",
      "50%             NaN             NaN             NaN  \n",
      "75%             NaN             NaN             NaN  \n",
      "max             NaN             NaN             NaN  \n",
      "\n",
      "[11 rows x 26 columns]\n",
      "\n",
      "V√©rification des colonnes date/heure :\n",
      "date_heure_reception_alerte : format date valide\n",
      " date_heure_fin_operation : format date NON valide\n",
      "=====================================================\n",
      "\n",
      "\n",
      "================ AUDIT : resultats_humain ================\n",
      "Nombre de lignes : 290544\n",
      "Nombre de colonnes : 5\n",
      "\n",
      "Colonnes :\n",
      "['operation_id', 'categorie_personne', 'resultat_humain', 'nombre', 'dont_nombre_blesse']\n",
      "\n",
      "Types des colonnes :\n",
      "operation_id           int64\n",
      "categorie_personne    object\n",
      "resultat_humain       object\n",
      "nombre                 int64\n",
      "dont_nombre_blesse     int64\n",
      "dtype: object\n",
      "\n",
      "Valeurs manquantes :\n",
      "operation_id          0\n",
      "categorie_personne    0\n",
      "resultat_humain       0\n",
      "nombre                0\n",
      "dont_nombre_blesse    0\n",
      "dtype: int64\n",
      "\n",
      "Nombre de doublons :\n",
      "0\n",
      "\n",
      "Statistiques descriptives :\n",
      "        operation_id categorie_personne    resultat_humain         nombre  \\\n",
      "count   2.905440e+05             290544             290544  290544.000000   \n",
      "unique           NaN                 10                 13            NaN   \n",
      "top              NaN  Toutes cat√©gories  Personne secourue            NaN   \n",
      "freq             NaN             118650             131533            NaN   \n",
      "mean    3.803402e+09                NaN                NaN       3.966401   \n",
      "std     7.483455e+09                NaN                NaN      16.422192   \n",
      "min    -1.356140e+05                NaN                NaN       0.000000   \n",
      "25%    -4.142225e+04                NaN                NaN       1.000000   \n",
      "50%     1.932025e+09                NaN                NaN       2.000000   \n",
      "75%     3.120051e+09                NaN                NaN       4.000000   \n",
      "max     1.104202e+11                NaN                NaN    3237.000000   \n",
      "\n",
      "        dont_nombre_blesse  \n",
      "count        290544.000000  \n",
      "unique                 NaN  \n",
      "top                    NaN  \n",
      "freq                   NaN  \n",
      "mean              0.097397  \n",
      "std               0.397674  \n",
      "min               0.000000  \n",
      "25%               0.000000  \n",
      "50%               0.000000  \n",
      "75%               0.000000  \n",
      "max              42.000000  \n",
      "\n",
      "V√©rification des colonnes date/heure :\n",
      "=====================================================\n",
      "\n",
      "\n",
      "================ AUDIT : flotteurs ================\n",
      "Nombre de lignes : 315191\n",
      "Nombre de colonnes : 7\n",
      "\n",
      "Colonnes :\n",
      "['operation_id', 'numero_ordre', 'pavillon', 'resultat_flotteur', 'type_flotteur', 'categorie_flotteur', 'numero_immatriculation']\n",
      "\n",
      "Types des colonnes :\n",
      "operation_id                int64\n",
      "numero_ordre              float64\n",
      "pavillon                   object\n",
      "resultat_flotteur          object\n",
      "type_flotteur              object\n",
      "categorie_flotteur         object\n",
      "numero_immatriculation     object\n",
      "dtype: object\n",
      "\n",
      "Valeurs manquantes :\n",
      "operation_id                   0\n",
      "numero_ordre               70398\n",
      "pavillon                   21796\n",
      "resultat_flotteur           4039\n",
      "type_flotteur               2606\n",
      "categorie_flotteur          2606\n",
      "numero_immatriculation    178607\n",
      "dtype: int64\n",
      "\n",
      "Nombre de doublons :\n",
      "189\n",
      "\n",
      "Statistiques descriptives :\n",
      "        operation_id   numero_ordre  pavillon resultat_flotteur  \\\n",
      "count   3.151910e+05  244793.000000    293395            311152   \n",
      "unique           NaN            NaN         2                16   \n",
      "top              NaN            NaN  Fran√ßais          Remorqu√©   \n",
      "freq             NaN            NaN    218352            124676   \n",
      "mean    3.642869e+09       1.029482       NaN               NaN   \n",
      "std     7.189393e+09       0.295728       NaN               NaN   \n",
      "min    -1.356140e+05       1.000000       NaN               NaN   \n",
      "25%    -3.979500e+04       1.000000       NaN               NaN   \n",
      "50%     2.119870e+09       1.000000       NaN               NaN   \n",
      "75%     3.120021e+09       1.000000       NaN               NaN   \n",
      "max     1.104202e+11      25.000000       NaN               NaN   \n",
      "\n",
      "            type_flotteur categorie_flotteur  \\\n",
      "count              312585             312585   \n",
      "unique                 31                  6   \n",
      "top     Plaisance √† voile          Plaisance   \n",
      "freq                77479             185462   \n",
      "mean                  NaN                NaN   \n",
      "std                   NaN                NaN   \n",
      "min                   NaN                NaN   \n",
      "25%                   NaN                NaN   \n",
      "50%                   NaN                NaN   \n",
      "75%                   NaN                NaN   \n",
      "max                   NaN                NaN   \n",
      "\n",
      "                          numero_immatriculation  \n",
      "count                                     136584  \n",
      "unique                                     86309  \n",
      "top     d5c85731deb8a6e1396ff29c8528931066ab40ea  \n",
      "freq                                        7429  \n",
      "mean                                         NaN  \n",
      "std                                          NaN  \n",
      "min                                          NaN  \n",
      "25%                                          NaN  \n",
      "50%                                          NaN  \n",
      "75%                                          NaN  \n",
      "max                                          NaN  \n",
      "\n",
      "V√©rification des colonnes date/heure :\n",
      "=====================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tables = {\n",
    "    \"operations\": operations,\n",
    "    \"resultats_humain\": resultats_humain,\n",
    "    \"flotteurs\": flotteurs\n",
    "}\n",
    "\n",
    "for name, df in tables.items():\n",
    "    audit_table(df, name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b79f937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== V√©rification des operation_id ===\n",
      "\n",
      "Table operations :\n",
      "- Nombre d'IDs uniques : 385782\n",
      "- IDs pr√©sents ici mais absents dans operations : set()\n",
      "\n",
      "Table resultats_humain :\n",
      "- Nombre d'IDs uniques : 282559\n",
      "- IDs pr√©sents ici mais absents dans operations : set()\n",
      "\n",
      "Table flotteurs :\n",
      "- Nombre d'IDs uniques : 309191\n",
      "- IDs pr√©sents ici mais absents dans operations : set()\n"
     ]
    }
   ],
   "source": [
    "print(\"=== V√©rification des operation_id ===\")\n",
    "\n",
    "if \"operation_id\" in operations.columns:\n",
    "    ops_ids = set(operations[\"operation_id\"])\n",
    "else:\n",
    "    ops_ids = set()\n",
    "\n",
    "for name, df in tables.items():\n",
    "    if \"operation_id\" in df.columns:\n",
    "        ids = set(df[\"operation_id\"])\n",
    "        print(f\"\\nTable {name} :\")\n",
    "        print(f\"- Nombre d'IDs uniques : {len(ids)}\")\n",
    "        print(f\"- IDs pr√©sents ici mais absents dans operations : {ids - ops_ids}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05d79286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R√©sum√© global \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table</th>\n",
       "      <th>rows</th>\n",
       "      <th>cols</th>\n",
       "      <th>missing_values</th>\n",
       "      <th>duplicates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>operations</td>\n",
       "      <td>385782</td>\n",
       "      <td>26</td>\n",
       "      <td>1470102</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>resultats_humain</td>\n",
       "      <td>290544</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flotteurs</td>\n",
       "      <td>315191</td>\n",
       "      <td>7</td>\n",
       "      <td>280052</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              table    rows  cols  missing_values  duplicates\n",
       "0        operations  385782    26         1470102           0\n",
       "1  resultats_humain  290544     5               0           0\n",
       "2         flotteurs  315191     7          280052         189"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( \"R√©sum√© global \")\n",
    "def resume_table(df, table_name):\n",
    "    return {\n",
    "        \"table\": table_name,\n",
    "        \"rows\": df.shape[0],\n",
    "        \"cols\": df.shape[1],\n",
    "        \"missing_values\": df.isna().sum().sum(),\n",
    "        \"duplicates\": df.duplicated().sum()\n",
    "    }\n",
    "\n",
    "resume_global = [resume_table(df, name) for name, df in tables.items()]\n",
    "pd.DataFrame(resume_global)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a16f5c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== V√©rification colonnes attendues : operations ===\n",
      "Colonnes manquantes : {'date', 'type', 'lieu'}\n",
      "Colonnes en trop : {'autorite', 'mer_force', 'zone_responsabilite', 'seconde_autorite', 'numero_sitrep', 'categorie_evenement', 'qui_alerte', 'est_metropolitain', 'systeme_source', 'vent_direction', 'latitude', 'moyen_alerte', 'departement', 'longitude', 'cross', 'date_heure_reception_alerte', 'pourquoi_alerte', 'categorie_qui_alerte', 'vent_force', 'evenement', 'cross_sitrep', 'date_heure_fin_operation', 'fuseau_horaire', 'type_operation', 'vent_direction_categorie'}\n",
      "\n",
      "=== V√©rification colonnes attendues : resultats_humain ===\n",
      "Colonnes manquantes : {'nb_sauves', 'nb_deces'}\n",
      "Colonnes en trop : {'dont_nombre_blesse', 'resultat_humain', 'categorie_personne', 'nombre'}\n",
      "\n",
      "=== V√©rification colonnes attendues : flotteurs ===\n",
      "Colonnes manquantes : {'etat', 'flotteur_id'}\n",
      "Colonnes en trop : {'numero_immatriculation', 'pavillon', 'numero_ordre', 'type_flotteur', 'categorie_flotteur', 'resultat_flotteur'}\n"
     ]
    }
   ],
   "source": [
    "expected_columns = {\n",
    "    \"operations\": [\"operation_id\", \"date\", \"type\", \"lieu\"],\n",
    "    \"resultats_humain\": [\"operation_id\", \"nb_sauves\", \"nb_deces\"],\n",
    "    \"flotteurs\": [\"operation_id\", \"flotteur_id\", \"etat\"]\n",
    "}\n",
    "\n",
    "for name, df in tables.items():\n",
    "    print(f\"\\n=== V√©rification colonnes attendues : {name} ===\")\n",
    "    missing = set(expected_columns[name]) - set(df.columns)\n",
    "    extra = set(df.columns) - set(expected_columns[name])\n",
    "    print(\"Colonnes manquantes :\", missing)\n",
    "    print(\"Colonnes en trop :\", extra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81a6ba25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== V√©rification avanc√©e des operation_id ===\n",
      "IDs uniques dans operations : 385782\n",
      "Doublons dans operations : 0\n",
      "\n",
      "Table operations : 0 IDs orphelins\n",
      "\n",
      "Table resultats_humain : 0 IDs orphelins\n",
      "\n",
      "Table flotteurs : 0 IDs orphelins\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== V√©rification avanc√©e des operation_id ===\")\n",
    "\n",
    "if \"operation_id\" in operations.columns:\n",
    "    ops_unique = operations[\"operation_id\"].nunique()\n",
    "    ops_dups = operations[\"operation_id\"].duplicated().sum()\n",
    "    print(f\"IDs uniques dans operations : {ops_unique}\")\n",
    "    print(f\"Doublons dans operations : {ops_dups}\")\n",
    "\n",
    "for name, df in tables.items():\n",
    "    if \"operation_id\" in df.columns:\n",
    "        orphan = set(df[\"operation_id\"]) - set(operations[\"operation_id\"])\n",
    "        print(f\"\\nTable {name} : {len(orphan)} IDs orphelins\")\n",
    "        if len(orphan) > 0:\n",
    "            print(orphan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2457341d",
   "metadata": {},
   "source": [
    "V√©rification de la cl√© commune operation_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3428f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operations : valeurs uniques operation_id = 385782\n",
      "resultats_humain : valeurs uniques operation_id = 282559\n",
      "flotteurs : valeurs uniques operation_id = 309191\n"
     ]
    }
   ],
   "source": [
    "for name, df in tables.items():\n",
    "    if \"operation_id\" in df.columns:\n",
    "        print(f\"{name} : valeurs uniques operation_id = {df['operation_id'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2afbcb9",
   "metadata": {},
   "source": [
    "v√©rifier coh√©rence entre tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc2f1a2",
   "metadata": {},
   "source": [
    "Table OPERATIONS ‚Äî Analyse\n",
    "‚úî Taille\n",
    "\n",
    "    385 782 lignes\n",
    "\n",
    "    26 colonnes\n",
    "\n",
    "‚úî Probl√®mes d√©tect√©s\n",
    "\n",
    "    Beaucoup de colonnes object (texte) ‚Üí normal.\n",
    "\n",
    "    Colonnes avec beaucoup de valeurs manquantes :\n",
    "\n",
    "        pourquoi_alerte ‚Üí 176k manquants\n",
    "\n",
    "        departement ‚Üí 76k manquants\n",
    "\n",
    "        seconde_autorite ‚Üí 370k manquants (quasi vide)\n",
    "\n",
    "        latitude / longitude ‚Üí 54k manquants\n",
    "\n",
    "        vent_direction, vent_force, mer_force ‚Üí 100k manquants\n",
    "\n",
    "‚û°Ô∏è Ces colonnes devront √™tre trait√©es dans le nettoyage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4358c17",
   "metadata": {},
   "source": [
    "‚úî Dates\n",
    "\n",
    "    date_heure_reception_alerte\n",
    "\n",
    "    date_heure_fin_operation\n",
    "\n",
    "Elles sont en string, mais le format semble valide (2025-06-11 22:50:00+00:00).\n",
    "\n",
    "‚û°Ô∏è √Ä convertir en datetime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce982e5",
   "metadata": {},
   "source": [
    "‚úî Valeurs aberrantes possibles\n",
    "\n",
    "    operation_id est n√©gatif ‚Üí est-ce normal ?\n",
    "    Probablement oui (identifiants internes CROSS)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952be3d4",
   "metadata": {},
   "source": [
    "Table OPERATIONS ‚Äî Analyse\n",
    "‚úî Taille\n",
    "\n",
    "    385 782 lignes\n",
    "\n",
    "    26 colonnes\n",
    "\n",
    "‚úî Probl√®mes d√©tect√©s\n",
    "\n",
    "    Beaucoup de colonnes object (texte) ‚Üí normal.\n",
    "\n",
    "    Colonnes avec beaucoup de valeurs manquantes :\n",
    "\n",
    "        pourquoi_alerte ‚Üí 176k manquants\n",
    "\n",
    "        departement ‚Üí 76k manquants\n",
    "\n",
    "        seconde_autorite ‚Üí 370k manquants (quasi vide)\n",
    "\n",
    "        latitude / longitude ‚Üí 54k manquants\n",
    "\n",
    "        vent_direction, vent_force, mer_force ‚Üí 100k manquants\n",
    "\n",
    "‚û°Ô∏è Ces colonnes devront √™tre trait√©es dans le nettoyage.\n",
    "‚úî Dates\n",
    "\n",
    "    date_heure_reception_alerte\n",
    "\n",
    "    date_heure_fin_operation\n",
    "\n",
    "Elles sont en string, mais le format semble valide (2025-06-11 22:50:00+00:00).\n",
    "\n",
    "‚û°Ô∏è √Ä convertir en datetime.\n",
    "‚úî Valeurs aberrantes possibles\n",
    "\n",
    "    operation_id est n√©gatif ‚Üí est-ce normal ?\n",
    "    Probablement oui (identifiants internes CROSS).\n",
    "\n",
    "üü¶ 3. Table RESULTATS HUMAIN ‚Äî Analyse\n",
    "‚úî Taille\n",
    "\n",
    "    290 544 lignes\n",
    "\n",
    "    5 colonnes\n",
    "\n",
    "‚úî Propret√©\n",
    "\n",
    "    Aucune valeur manquante\n",
    "\n",
    "    Types coh√©rents\n",
    "\n",
    "    operation_id toujours pr√©sent\n",
    "\n",
    "‚û°Ô∏è Cette table est propre.\n",
    "üü¶ 4. Table FLOTTEURS ‚Äî Analyse\n",
    "‚úî Taille\n",
    "\n",
    "    315 191 lignes\n",
    "\n",
    "    7 colonnes\n",
    "\n",
    "‚úî Probl√®mes d√©tect√©s\n",
    "\n",
    "    numero_ordre ‚Üí 70k valeurs manquantes\n",
    "\n",
    "    numero_immatriculation ‚Üí 180k manquants\n",
    "\n",
    "    pavillon ‚Üí 20k manquants\n",
    "\n",
    "‚û°Ô∏è Colonnes √† nettoyer ou √† laisser en nullable.\n",
    "üü¶ 5. Interpr√©tation globale\n",
    "‚úî Les trois tables sont coh√©rentes\n",
    "\n",
    "Elles ont toutes un operation_id.\n",
    "‚úî Beaucoup de valeurs manquantes dans OPERATIONS\n",
    "\n",
    "C‚Äôest normal pour des donn√©es op√©rationnelles.\n",
    "‚úî Les dates sont en string\n",
    "\n",
    "√Ä convertir.\n",
    "‚úî Les types sont corrects sauf quelques colonnes mixtes\n",
    "\n",
    "√Ä nettoyer avant Pandera.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "746f5a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== OPERATIONS ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_values</th>\n",
       "      <th>missing_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>operation_id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_operation</th>\n",
       "      <td>176441</td>\n",
       "      <td>45.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pourquoi_alerte</th>\n",
       "      <td>209341</td>\n",
       "      <td>54.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moyen_alerte</th>\n",
       "      <td>1892</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qui_alerte</th>\n",
       "      <td>1728</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categorie_qui_alerte</th>\n",
       "      <td>1728</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cross</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>departement</th>\n",
       "      <td>76484</td>\n",
       "      <td>19.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>est_metropolitain</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evenement</th>\n",
       "      <td>3923</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categorie_evenement</th>\n",
       "      <td>3923</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>autorite</th>\n",
       "      <td>80103</td>\n",
       "      <td>20.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seconde_autorite</th>\n",
       "      <td>370746</td>\n",
       "      <td>96.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zone_responsabilite</th>\n",
       "      <td>715</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>54462</td>\n",
       "      <td>14.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>54462</td>\n",
       "      <td>14.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vent_direction</th>\n",
       "      <td>103985</td>\n",
       "      <td>26.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vent_direction_categorie</th>\n",
       "      <td>115028</td>\n",
       "      <td>29.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vent_force</th>\n",
       "      <td>103928</td>\n",
       "      <td>26.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mer_force</th>\n",
       "      <td>111213</td>\n",
       "      <td>28.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_heure_reception_alerte</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_heure_fin_operation</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numero_sitrep</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cross_sitrep</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuseau_horaire</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>systeme_source</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             missing_values  missing_percent\n",
       "operation_id                              0             0.00\n",
       "type_operation                       176441            45.74\n",
       "pourquoi_alerte                      209341            54.26\n",
       "moyen_alerte                           1892             0.49\n",
       "qui_alerte                             1728             0.45\n",
       "categorie_qui_alerte                   1728             0.45\n",
       "cross                                     0             0.00\n",
       "departement                           76484            19.83\n",
       "est_metropolitain                         0             0.00\n",
       "evenement                              3923             1.02\n",
       "categorie_evenement                    3923             1.02\n",
       "autorite                              80103            20.76\n",
       "seconde_autorite                     370746            96.10\n",
       "zone_responsabilite                     715             0.19\n",
       "latitude                              54462            14.12\n",
       "longitude                             54462            14.12\n",
       "vent_direction                       103985            26.95\n",
       "vent_direction_categorie             115028            29.82\n",
       "vent_force                           103928            26.94\n",
       "mer_force                            111213            28.83\n",
       "date_heure_reception_alerte               0             0.00\n",
       "date_heure_fin_operation                  0             0.00\n",
       "numero_sitrep                             0             0.00\n",
       "cross_sitrep                              0             0.00\n",
       "fuseau_horaire                            0             0.00\n",
       "systeme_source                            0             0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESULTATS HUMAIN ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_values</th>\n",
       "      <th>missing_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>operation_id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categorie_personne</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resultat_humain</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nombre</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dont_nombre_blesse</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    missing_values  missing_percent\n",
       "operation_id                     0              0.0\n",
       "categorie_personne               0              0.0\n",
       "resultat_humain                  0              0.0\n",
       "nombre                           0              0.0\n",
       "dont_nombre_blesse               0              0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FLOTTEURS ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_values</th>\n",
       "      <th>missing_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>operation_id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numero_ordre</th>\n",
       "      <td>70398</td>\n",
       "      <td>22.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pavillon</th>\n",
       "      <td>21796</td>\n",
       "      <td>6.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resultat_flotteur</th>\n",
       "      <td>4039</td>\n",
       "      <td>1.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_flotteur</th>\n",
       "      <td>2606</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categorie_flotteur</th>\n",
       "      <td>2606</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numero_immatriculation</th>\n",
       "      <td>178607</td>\n",
       "      <td>56.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        missing_values  missing_percent\n",
       "operation_id                         0             0.00\n",
       "numero_ordre                     70398            22.34\n",
       "pavillon                         21796             6.92\n",
       "resultat_flotteur                 4039             1.28\n",
       "type_flotteur                     2606             0.83\n",
       "categorie_flotteur                2606             0.83\n",
       "numero_immatriculation          178607            56.67"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def missing_percentage(df):\n",
    "    missing = df.isna().sum()\n",
    "    total = len(df)\n",
    "    percent = (missing / total) * 100\n",
    "    return pd.DataFrame({\n",
    "        \"missing_values\": missing,\n",
    "        \"missing_percent\": percent.round(2)\n",
    "    })\n",
    "\n",
    "print(\"=== OPERATIONS ===\")\n",
    "display(missing_percentage(operations))\n",
    "\n",
    "print(\"\\n=== RESULTATS HUMAIN ===\")\n",
    "display(missing_percentage(resultats_humain))\n",
    "\n",
    "print(\"\\n=== FLOTTEURS ===\")\n",
    "display(missing_percentage(flotteurs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22c5fc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latitude hors limites : 0\n",
      "Longitude hors limites : 0\n",
      "Vent direction aberrant : 0\n",
      "Vent force n√©gative : 0\n",
      "Mer force n√©gative : 0\n"
     ]
    },
    {
     "ename": "OutOfBoundsDatetime",
     "evalue": "Out of bounds nanosecond timestamp: 1318-01-02 00:00:00",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/arrays/datetimes.py:2236\u001b[0m, in \u001b[0;36mobjects_to_datetime64ns\u001b[0;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[1;32m   2235\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2236\u001b[0m     values, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mconversion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatetime_to_datetime64\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mK\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2237\u001b[0m     \u001b[38;5;66;03m# If tzaware, these values represent unix timestamps, so we\u001b[39;00m\n\u001b[1;32m   2238\u001b[0m     \u001b[38;5;66;03m#  return them as i8 to distinguish from wall times\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/_libs/tslibs/conversion.pyx:360\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion.datetime_to_datetime64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Unrecognized value type: <class 'str'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOutOfBoundsDatetime\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m ops_dates \u001b[38;5;241m=\u001b[39m operations\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     12\u001b[0m ops_dates[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(ops_dates[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_heure_reception_alerte\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 13\u001b[0m ops_dates[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mops_dates\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate_heure_fin_operation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDates incoh√©rentes :\u001b[39m\u001b[38;5;124m\"\u001b[39m, ops_dates[ops_dates[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m ops_dates[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Flotteurs\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:1051\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1051\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[38;5;241m.\u001b[39mMutableMapping)):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:402\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m infer_datetime_format\n\u001b[1;32m    401\u001b[0m utc \u001b[38;5;241m=\u001b[39m tz \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 402\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mobjects_to_datetime64ns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequire_iso8601\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequire_iso8601\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n\u001b[1;32m    415\u001b[0m     dta \u001b[38;5;241m=\u001b[39m DatetimeArray(result, dtype\u001b[38;5;241m=\u001b[39mtz_to_dtype(tz_parsed))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/arrays/datetimes.py:2242\u001b[0m, in \u001b[0;36mobjects_to_datetime64ns\u001b[0;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[1;32m   2240\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m values\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi8\u001b[39m\u001b[38;5;124m\"\u001b[39m), tz_parsed\n\u001b[1;32m   2241\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m-> 2242\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m   2244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2245\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m   2246\u001b[0m     \u001b[38;5;66;03m#  is in UTC\u001b[39;00m\n\u001b[1;32m   2247\u001b[0m     \u001b[38;5;66;03m# Return i8 values to denote unix timestamps\u001b[39;00m\n\u001b[1;32m   2248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi8\u001b[39m\u001b[38;5;124m\"\u001b[39m), tz_parsed\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/arrays/datetimes.py:2224\u001b[0m, in \u001b[0;36mobjects_to_datetime64ns\u001b[0;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[1;32m   2222\u001b[0m order: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m flags\u001b[38;5;241m.\u001b[39mf_contiguous \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2223\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2224\u001b[0m     result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mtslib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_to_datetime\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mK\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2226\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2229\u001b[0m \u001b[43m        \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequire_iso8601\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequire_iso8601\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_mixed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_mixed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2232\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2233\u001b[0m     result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mreshape(data\u001b[38;5;241m.\u001b[39mshape, order\u001b[38;5;241m=\u001b[39morder)\n\u001b[1;32m   2234\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/_libs/tslib.pyx:381\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/_libs/tslib.pyx:608\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/_libs/tslib.pyx:604\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/_libs/tslib.pyx:580\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/_libs/tslibs/np_datetime.pyx:120\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.np_datetime.check_dts_bounds\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOutOfBoundsDatetime\u001b[0m: Out of bounds nanosecond timestamp: 1318-01-02 00:00:00"
     ]
    }
   ],
   "source": [
    "# Valeurs aberrantes latitude / longitude\n",
    "print(\"Latitude hors limites :\", operations[(operations['latitude'] > 90) | (operations['latitude'] < -90)].shape[0])\n",
    "print(\"Longitude hors limites :\", operations[(operations['longitude'] > 180) | (operations['longitude'] < -180)].shape[0])\n",
    "\n",
    "# Valeurs aberrantes m√©t√©o\n",
    "print(\"Vent direction aberrant :\", operations[(operations['vent_direction'] < 0) | (operations['vent_direction'] > 360)].shape[0])\n",
    "print(\"Vent force n√©gative :\", operations[operations['vent_force'] < 0].shape[0])\n",
    "print(\"Mer force n√©gative :\", operations[operations['mer_force'] < 0].shape[0])\n",
    "\n",
    "# Dates incoh√©rentes\n",
    "ops_dates = operations.copy()\n",
    "ops_dates['start'] = pd.to_datetime(ops_dates['date_heure_reception_alerte'])\n",
    "ops_dates['end'] = pd.to_datetime(ops_dates['date_heure_fin_operation'])\n",
    "print(\"Dates incoh√©rentes :\", ops_dates[ops_dates['end'] < ops_dates['start']].shape[0])\n",
    "\n",
    "# Flotteurs\n",
    "print(\"Numero ordre n√©gatif :\", flotteurs[flotteurs['numero_ordre'] < 0].shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245d0b4d",
   "metadata": {},
   "source": [
    "Voici une **interpr√©tation ** des r√©sultats obtenus  \n",
    " \n",
    "Il synth√©tise **tout l‚Äôaudit**, et pr√©pare parfaitement la section ‚ÄúNettoyage‚Äù.\n",
    "\n",
    "---\n",
    "\n",
    "# üßæ **Interpr√©tation compl√®te des r√©sultats de l‚Äôaudit**\n",
    "\n",
    "L‚Äôaudit des trois tables (`operations`, `resultats_humain`, `flotteurs`) met en √©vidence la structure, la qualit√© et la coh√©rence des donn√©es avant la phase de nettoyage.  \n",
    "Les r√©sultats permettent d‚Äôidentifier les colonnes probl√©matiques, les incoh√©rences potentielles et les transformations n√©cessaires pour la suite du pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "## üìå **1. Table `operations`**\n",
    "\n",
    "### **Structure g√©n√©rale**\n",
    "- **385 782 lignes**, **26 colonnes**\n",
    "- Colonnes majoritairement de type `object` (texte), quelques colonnes num√©riques (`float64`, `int64`) et une colonne bool√©enne (`est_metropolitain`)\n",
    "\n",
    "### **Qualit√© des donn√©es**\n",
    "- **1 470 102 valeurs manquantes** au total  \n",
    "  ‚Üí c‚Äôest la table la plus incompl√®te du dataset\n",
    "- Colonnes tr√®s incompl√®tes :\n",
    "  - `pourquoi_alerte`\n",
    "  - `departement`\n",
    "  - `seconde_autorite` (quasi vide)\n",
    "  - `latitude`, `longitude`\n",
    "  - `vent_direction`, `vent_force`, `mer_force`\n",
    "- Colonnes de dates (`date_heure_reception_alerte`, `date_heure_fin_operation`) au format texte mais **format valide**\n",
    "- **Aucun doublon** d√©tect√©\n",
    "- **Aucun ID orphelin** ‚Üí tous les `operation_id` existent dans cette table\n",
    "\n",
    "### **Colonnes attendues vs colonnes r√©elles**\n",
    "- Colonnes attendues manquantes : `date`, `lieu`, `type`  \n",
    "  ‚Üí Ces colonnes n‚Äôexistent pas dans le dataset r√©el  \n",
    "- Colonnes ‚Äúen trop‚Äù : toutes les colonnes m√©tier r√©elles  \n",
    "  ‚Üí Cela montre que le dictionnaire attendu n‚Äôest pas align√© avec les donn√©es fournies\n",
    "\n",
    "### **Conclusion**\n",
    "La table `operations` est riche mais h√©t√©rog√®ne, avec beaucoup de valeurs manquantes et des colonnes complexes.  \n",
    "Elle n√©cessitera un nettoyage approfondi, notamment sur :\n",
    "- les types\n",
    "- les dates\n",
    "- les colonnes g√©ographiques\n",
    "- les colonnes m√©t√©o\n",
    "- les colonnes d‚Äôautorit√©\n",
    "\n",
    "---\n",
    "\n",
    "## üìå **2. Table `resultats_humain`**\n",
    "\n",
    "### **Structure g√©n√©rale**\n",
    "- **290 544 lignes**, **5 colonnes**\n",
    "\n",
    "### **Qualit√© des donn√©es**\n",
    "- **0 valeur manquante**\n",
    "- Types coh√©rents (`int64` et `object`)\n",
    "- Aucun doublon\n",
    "- Aucun ID orphelin\n",
    "\n",
    "### **Colonnes attendues vs r√©elles**\n",
    "- Colonnes attendues manquantes : `nb_sauves`, `nb_deces`\n",
    "- Colonnes pr√©sentes : `categorie_personne`, `resultat_humain`, `nombre`, `dont_nombre_blesse`\n",
    "\n",
    "‚û°Ô∏è Le dictionnaire attendu ne correspond pas aux donn√©es r√©elles.  \n",
    "‚û°Ô∏è Il faudra adapter le sch√©ma Pandera et le mod√®le SQL √† la r√©alit√© des donn√©es.\n",
    "\n",
    "### **Conclusion**\n",
    "Table propre, exploitable imm√©diatement apr√®s harmonisation des noms de colonnes.\n",
    "\n",
    "---\n",
    "\n",
    "## üìå **3. Table `flotteurs`**\n",
    "\n",
    "### **Structure g√©n√©rale**\n",
    "- **315 191 lignes**, **7 colonnes**\n",
    "\n",
    "### **Qualit√© des donn√©es**\n",
    "- **280 052 valeurs manquantes**\n",
    "- 189 doublons d√©tect√©s\n",
    "- Colonnes incompl√®tes :\n",
    "  - `numero_ordre`\n",
    "  - `pavillon`\n",
    "  - `numero_immatriculation`\n",
    "\n",
    "### **Colonnes attendues vs r√©elles**\n",
    "- Colonnes attendues manquantes : `etat`, `flotteur_id`\n",
    "- Colonnes pr√©sentes : `pavillon`, `numero_ordre`, `categorie_flotteur`, etc.\n",
    "\n",
    "‚û°Ô∏è Comme pour les autres tables, le dictionnaire attendu ne correspond pas aux donn√©es r√©elles.\n",
    "\n",
    "### **Conclusion**\n",
    "Table globalement exploitable, mais n√©cessitant :\n",
    "- suppression ou traitement des doublons\n",
    "- gestion des valeurs manquantes\n",
    "- harmonisation des colonnes\n",
    "\n",
    "---\n",
    "\n",
    "## üìå **4. Coh√©rence de la cl√© `operation_id`**\n",
    "\n",
    "### **R√©sultats**\n",
    "- `operations` : **385 782 IDs uniques**\n",
    "- `resultats_humain` : **282 559 IDs uniques**\n",
    "- `flotteurs` : **309 191 IDs uniques**\n",
    "- **0 ID orphelin dans les deux tables secondaires**\n",
    "- **0 doublon dans `operations`**\n",
    "\n",
    "### **Conclusion**\n",
    "`operation_id` est une **cl√© primaire fiable** dans `operations`  \n",
    "et une **cl√© √©trang√®re coh√©rente** dans les deux autres tables.\n",
    "\n",
    "Cela valide la possibilit√© de :\n",
    "- cr√©er un sch√©ma relationnel propre (PostgreSQL)\n",
    "- faire des jointures fiables\n",
    "- construire un mod√®le analytique robuste\n",
    "\n",
    "---\n",
    "\n",
    "## üìå **5. Synth√®se g√©n√©rale**\n",
    "\n",
    "| Table | Lignes | Colonnes | Valeurs manquantes | Doublons | Qualit√© |\n",
    "|-------|--------|----------|---------------------|----------|---------|\n",
    "| operations | 385 782 | 26 | 1 470 102 | 0 | ‚ö†Ô∏è Tr√®s h√©t√©rog√®ne |\n",
    "| resultats_humain | 290 544 | 5 | 0 | 0 | ‚úî Propre |\n",
    "| flotteurs | 315 191 | 7 | 280 052 | 189 | ‚ö†Ô∏è Moyenne |\n",
    "\n",
    "---\n",
    "\n",
    "## üìå **6. Implications pour le nettoyage**\n",
    "\n",
    "Les r√©sultats de l‚Äôaudit montrent que les actions suivantes seront n√©cessaires :\n",
    "\n",
    "### üîß **Nettoyage des types**\n",
    "- Conversion des dates en `datetime`\n",
    "- Harmonisation des colonnes mixtes (`object` + `float`)\n",
    "\n",
    "### üîß **Gestion des valeurs manquantes**\n",
    "- D√©cider des colonnes √† conserver ou supprimer\n",
    "- Imputation ou suppression selon pertinence m√©tier\n",
    "\n",
    "### üîß **Nettoyage des doublons**\n",
    "- Suppression des 189 doublons dans `flotteurs`\n",
    "\n",
    "### üîß **Harmonisation des colonnes**\n",
    "- Adapter les sch√©mas Pandera aux colonnes r√©elles\n",
    "- Renommer certaines colonnes si n√©cessaire\n",
    "\n",
    "### üîß **Pr√©paration du sch√©ma SQL**\n",
    "- `operations` ‚Üí table principale (PK = operation_id)\n",
    "- `resultats_humain` ‚Üí table secondaire (FK = operation_id)\n",
    "- `flotteurs` ‚Üí table secondaire (FK = operation_id)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54175312",
   "metadata": {},
   "source": [
    "PARTIE NETTOYAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c6bdd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 1. Nettoyage de OPERATIONS\n",
    "# ============================\n",
    "\n",
    "# --- Convertir les dates (avec gestion des dates aberrantes)\n",
    "operations['date_heure_reception_alerte'] = pd.to_datetime(\n",
    "    operations['date_heure_reception_alerte'], errors='coerce'\n",
    ")\n",
    "\n",
    "operations['date_heure_fin_operation'] = pd.to_datetime(\n",
    "    operations['date_heure_fin_operation'], errors='coerce'\n",
    ")\n",
    "\n",
    "# --- Convertir les colonnes num√©riques\n",
    "numeric_cols_ops = [\n",
    "    'latitude', 'longitude',\n",
    "    'vent_direction', 'vent_force', 'mer_force'\n",
    "]\n",
    "\n",
    "for col in numeric_cols_ops:\n",
    "    if col in operations.columns:\n",
    "        operations[col] = pd.to_numeric(operations[col], errors='coerce')\n",
    "\n",
    "# --- Harmoniser les colonnes texte\n",
    "text_cols_ops = [\n",
    "    'type_operation', 'pourquoi_alerte', 'moyen_alerte', 'qui_alerte',\n",
    "    'categorie_qui_alerte', 'cross', 'departement', 'evenement',\n",
    "    'categorie_evenement', 'autorite', 'seconde_autorite',\n",
    "    'zone_responsabilite', 'vent_direction_categorie',\n",
    "    'cross_sitrep', 'fuseau_horaire', 'systeme_source'\n",
    "]\n",
    "\n",
    "for col in text_cols_ops:\n",
    "    if col in operations.columns:\n",
    "        operations[col] = operations[col].astype('string')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7ad1fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 2. Nettoyage de FLOTTEURS\n",
    "# ============================\n",
    "\n",
    "# --- Supprimer les doublons\n",
    "flotteurs = flotteurs.drop_duplicates()\n",
    "\n",
    "# --- Convertir les colonnes num√©riques\n",
    "if 'numero_ordre' in flotteurs.columns:\n",
    "    flotteurs['numero_ordre'] = pd.to_numeric(flotteurs['numero_ordre'], errors='coerce')\n",
    "\n",
    "# --- Harmoniser les colonnes texte\n",
    "text_cols_flot = [\n",
    "    'pavillon', 'resultat_flotteur', 'type_flotteur',\n",
    "    'categorie_flotteur', 'numero_immatriculation'\n",
    "]\n",
    "\n",
    "for col in text_cols_flot:\n",
    "    if col in flotteurs.columns:\n",
    "        flotteurs[col] = flotteurs[col].astype('string')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71df0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 3. Nettoyage de RESULTATS_HUMAIN\n",
    "# ============================\n",
    "\n",
    "text_cols_res = ['resultat_flotteur']\n",
    "\n",
    "for col in text_cols_res:\n",
    "    if col in resultats_humain.columns:\n",
    "        resultats_humain[col] = resultats_humain[col].astype('string')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6da81f52",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [26], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# enregistrement des tavles\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43moperations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/operations_clean.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m flotteurs\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/flotteurs_clean.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m resultats_humain\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/resultats_humain_clean.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/generic.py:3551\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3540\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3542\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3543\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3544\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3548\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3549\u001b[0m )\n\u001b[0;32m-> 3551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3552\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3553\u001b[0m \u001b[43m    \u001b[49m\u001b[43mline_terminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mline_terminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3554\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3556\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3557\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3558\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3559\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3560\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3561\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3562\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3565\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3568\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/io/formats/format.py:1180\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1159\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1162\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1163\u001b[0m     line_terminator\u001b[38;5;241m=\u001b[39mline_terminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1179\u001b[0m )\n\u001b[0;32m-> 1180\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/io/formats/csvs.py:241\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    249\u001b[0m \n\u001b[1;32m    250\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    252\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    253\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mline_terminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    259\u001b[0m     )\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/io/common.py:694\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 694\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    698\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/io/common.py:568\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    566\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'data'"
     ]
    }
   ],
   "source": [
    "# enregistrement des tavles\n",
    "\n",
    "operations.to_csv(\"data/operations_clean.csv\", index=False)\n",
    "flotteurs.to_csv(\"data/flotteurs_clean.csv\", index=False)\n",
    "resultats_humain.to_csv(\"data/resultats_humain_clean.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
